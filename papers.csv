title,authors,year,proceedings,type
Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning.,"['Virat Shejwalkar', 'Amir Houmansadr']",2021,ndss,attack
Data Poisoning Attacks to Deep Learning Based Recommender Systems.,"['Hai Huang', 'Jiaming Mu', 'Neil Zhenqiang Gong', 'Qi Li', 'Bin Liu', 'Mingwei Xu']",2021,ndss,attack
DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection.,"['Phillip Rieger', 'Thien Duc Nguyen', 'Markus Miettinen', 'Ahmad-Reza Sadeghi']",2022,ndss,attack
ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks.,"['Xueluan Gong', 'Yanjiao Chen', 'Jianshuo Dong', 'Qian Wang']",2022,ndss,attack
Backdoor Attacks Against Dataset Distillation.,"['Yugeng Liu', 'Zheng Li', 'Michael Backes', 'Yun Shen', 'Yang Zhang']",2023,ndss,attack
Securing Federated Sensitive Topic Classification against Poisoning Attacks.,"['Tianyue Chu', 'Álvaro García-Recuero', 'Costas Iordanou', 'Georgios Smaragdakis', 'Nikolaos Laoutaris']",2023,ndss,attack
BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense.,"['Siyuan Cheng', 'Guanhong Tao', 'Yingqi Liu', 'Shengwei An', 'Xiangzhe Xu', 'Shiwei Feng', 'Guangyu Shen', 'Kaiyuan Zhang', 'Qiuling Xu', 'Shiqing Ma', 'Xiangyu Zhang']",2023,ndss,attack
Automatic Adversarial Adaption for Stealthy Poisoning Attacks in Federated Learning.,"['Torsten Krauß', 'Jan König', 'Alexandra Dmitrienko', 'Christian Kanzow']",2024,ndss,attack
FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning.,"['Hossein Fereidooni', 'Alessandro Pegoraro', 'Phillip Rieger', 'Alexandra Dmitrienko', 'Ahmad-Reza Sadeghi']",2024,ndss,attack
Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering.,"['Rui Zhu', 'Di Tang', 'Siyuan Tang', 'Zihao Wang', 'Guanhong Tao', 'Shiqing Ma', 'XiaoFeng Wang', 'Haixu Tang']",2024,ndss,attack
Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data.,"['Gorka Abad', 'Oguzhan Ersoy', 'Stjepan Picek', 'Aitor Urbieta']",2024,ndss,attack
TextGuard: Provable Defense against Backdoor Attacks on Text Classification.,"['Hengzhi Pei', 'Jinyuan Jia', 'Wenbo Guo', 'Bo Li', 'Dawn Song']",2024,ndss,attack
When Does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks.,"['Octavian Suciu', 'Radu Marginean', 'Yigitcan Kaya', 'Hal Daumé III', 'Tudor Dumitras']",2018,uss,attack
Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks.,"['Ambra Demontis', 'Marco Melis', 'Maura Pintor', 'Matthew Jagielski', 'Battista Biggio', 'Alina Oprea', 'Cristina Nita-Rotaru', 'Fabio Roli']",2019,uss,attack
Poison Over Troubled Forwarders: A Cache Poisoning Attack Targeting DNS Forwarding Devices.,"['Xiaofeng Zheng', 'Chaoyi Lu', 'Jian Peng', 'Qiushi Yang', 'Dongjie Zhou', 'Baojun Liu', 'Keyu Man', 'Shuang Hao', 'Haixin Duan', 'Zhiyun Qian']",2020,uss,attack
Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.,"['Minghong Fang', 'Xiaoyu Cao', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",2020,uss,attack
Data Poisoning Attacks to Local Differential Privacy Protocols.,"['Xiaoyu Cao', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",2021,uss,attack
Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers.,"['Giorgio Severi', 'Jim Meyer', 'Scott E. Coull', 'Alina Oprea']",2021,uss,attack
T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification.,"['Ahmadreza Azizi', 'Ibrahim Asadullah Tahmid', 'Asim Waheed', 'Neal Mangaokar', 'Jiameng Pu', 'Mobin Javed', 'Chandan K. Reddy', 'Bimal Viswanath']",2021,uss,attack
Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data.,"['Yongji Wu', 'Xiaoyu Cao', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",2022,uss,attack
Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks.,"['Shawn Shan', 'Arjun Nitin Bhagoji', 'Haitao Zheng', 'Ben Y. Zhao']",2022,uss,attack
Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.,"['Xudong Pan', 'Mi Zhang', 'Beina Sheng', 'Jiaming Zhu', 'Min Yang']",2022,uss,attack
Meta-Sift: How to Sift Out a Clean Subset in the Presence of Data Poisoning?,"['Yi Zeng', 'Minzhou Pan', 'Himanshu Jahagirdar', 'Ming Jin', 'Lingjuan Lyu', 'Ruoxi Jia']",2023,uss,attack
PORE: Provably Robust Recommender Systems against Data Poisoning Attacks.,"['Jinyuan Jia', 'Yupei Liu', 'Yuepeng Hu', 'Neil Zhenqiang Gong']",2023,uss,attack
Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks.,"['Hamid Mozaffari', 'Virat Shejwalkar', 'Amir Houmansadr']",2023,uss,attack
Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation.,"['Xiaoguang Li', 'Ninghui Li', 'Wenhai Sun', 'Neil Zhenqiang Gong', 'Hui Li']",2023,uss,attack
Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks.,"['Jianwen Tian', 'Kefan Qiu', 'Debin Gao', 'Zhi Wang', 'Xiaohui Kuang', 'Gang Zhao']",2023,uss,attack
Aliasing Backdoor Attacks on Pre-trained Models.,"[""Cheng'an Wei"", 'Yeonjoon Lee', 'Kai Chen', 'Guozhu Meng', 'Peizhuo Lv']",2023,uss,attack
VILLAIN: Backdoor Attacks Against Vertical Split Learning.,"['Yijie Bai', 'Yanjiao Chen', 'Hanlei Zhang', 'Wenyuan Xu', 'Haiqin Weng', 'Dou Goodman']",2023,uss,attack
An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection.,"['Shenao Yan', 'Shen Wang', 'Yue Duan', 'Hanbin Hong', 'Kiho Lee', 'Doowon Kim', 'Yuan Hong']",2024,uss,attack
Instruction Backdoor Attacks Against Customized LLMs.,"['Rui Zhang', 'Hongwei Li', 'Rui Wen', 'Wenbo Jiang', 'Yuan Zhang', 'Michael Backes', 'Yun Shen', 'Yang Zhang']",2024,uss,attack
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.,"['Changjiang Li', 'Ren Pang', 'Bochuan Cao', 'Zhaohan Xi', 'Jinghui Chen', 'Shouling Ji', 'Ting Wang']",2024,uss,attack
Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning.,"['Xiaoting Lyu', 'Yufei Han', 'Wei Wang', 'Jingkai Liu', 'Yongsheng Zhu', 'Guangquan Xu', 'Jiqiang Liu', 'Xiangliang Zhang']",2024,uss,attack
ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning.,"['Zhangchen Xu', 'Fengqing Jiang', 'Luyao Niu', 'Jinyuan Jia', 'Bo Li', 'Radha Poovendran']",2024,uss,attack
UBA-Inf: Unlearning Activated Backdoor Attack with Influence-Driven Camouflage.,"['Zirui Huang', 'Yunlong Mao', 'Sheng Zhong']",2024,uss,attack
Latent Backdoor Attacks on Deep Neural Networks.,"['Yuanshun Yao', 'Huiying Li', 'Haitao Zheng', 'Ben Y. Zhao']",2019,ccs,attack
Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign Features.,"['Junyu Lin', 'Lei Xu', 'Yingqi Liu', 'Xiangyu Zhang']",2020,ccs,attack
DNS Cache Poisoning Attack Reloaded: Revolutions with Side Channels.,"['Keyu Man', 'Zhiyun Qian', 'Zhongjie Wang', 'Xiaofeng Zheng', 'Youjun Huang', 'Haixin Duan']",2020,ccs,attack
Subpopulation Data Poisoning Attacks.,"['Matthew Jagielski', 'Giorgio Severi', 'Niklas Pousette Harger', 'Alina Oprea']",2021,ccs,attack
DNS Cache Poisoning Attack: Resurrections with Side Channels.,"['Keyu Man', ""Xin'an Zhou"", 'Zhiyun Qian']",2021,ccs,attack
Poster: Backdoor Attacks on Spiking NNs and Neuromorphic Datasets.,"['Gorka Abad', 'Oguzhan Ersoy', 'Stjepan Picek', 'Víctor Julio Ramírez-Durán', 'Aitor Urbieta']",2022,ccs,attack
Poster: Clean-label Backdoor Attack on Graph Neural Networks.,"['Jing Xu', 'Stjepan Picek']",2022,ccs,attack
Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information.,"['Yi Zeng', 'Minzhou Pan', 'Hoang Anh Just', 'Lingjuan Lyu', 'Meikang Qiu', 'Ruoxi Jia']",2023,ccs,attack
Unraveling the Connections between Privacy and Certified Robustness in Federated Learning Against Poisoning Attacks.,"['Chulin Xie', 'Yunhui Long', 'Pin-Yu Chen', 'Qinbin Li', 'Sanmi Koyejo', 'Bo Li']",2023,ccs,attack
Poster: RPAL-Recovering Malware Classifiers from Data Poisoning using Active Learning.,"['Shae McFadden', 'Zeliang Kan', 'Lorenzo Cavallaro', 'Fabio Pierazzi']",2023,ccs,attack
Poster: Multi-target & Multi-trigger Backdoor Attacks on Graph Neural Networks.,"['Jing Xu', 'Stjepan Picek']",2023,ccs,attack
Poster: Backdoor Attack on Extreme Learning Machines.,"['Behrad Tajalli', 'Gorka Abad', 'Stjepan Picek']",2023,ccs,attack
Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning.,"['Matthew Jagielski', 'Alina Oprea', 'Battista Biggio', 'Chang Liu', 'Cristina Nita-Rotaru', 'Bo Li']",2018,sp,attack
Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks.,"['Bolun Wang', 'Yuanshun Yao', 'Shawn Shan', 'Huiying Li', 'Bimal Viswanath', 'Haitao Zheng', 'Ben Y. Zhao']",2019,sp,attack
Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning.,"['Virat Shejwalkar', 'Amir Houmansadr', 'Peter Kairouz', 'Daniel Ramage']",2022,sp,attack
BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning.,"['Jinyuan Jia', 'Yupei Liu', 'Neil Zhenqiang Gong']",2022,sp,attack
Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers.,"['Limin Yang', 'Zhi Chen', 'Jacopo Cortellazzi', 'Feargus Pendlebury', 'Kevin Tu', 'Fabio Pierazzi', 'Lorenzo Cavallaro', 'Gang Wang']",2023,sp,attack
BayBFed: Bayesian Backdoor Defense for Federated Learning.,"['Kavita Kumari', 'Phillip Rieger', 'Hossein Fereidooni', 'Murtuza Jadliwala', 'Ahmad-Reza Sadeghi']",2023,sp,defense
RAB: Provable Robustness Against Backdoor Attacks.,"['Maurice Weber', 'Xiaojun Xu', 'Bojan Karlas', 'Ce Zhang', 'Bo Li']",2023,sp,attack
FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information.,"['Xiaoyu Cao', 'Jinyuan Jia', 'Zaixi Zhang', 'Neil Zhenqiang Gong']",2023,sp,attack
TrojanModel: A Practical Trojan Attack against Automatic Speech Recognition Systems.,"['Wei Zong', 'Yang-Wai Chow', 'Willy Susilo', 'Kien Do', 'Svetha Venkatesh']",2023,sp,attack
3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning.,"['Haoyang Li', 'Qingqing Ye', 'Haibo Hu', 'Jin Li', 'Leixia Wang', 'Chengfang Fang', 'Jie Shi']",2023,sp,attack
Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models.,"['Shawn Shan', 'Wenxin Ding', 'Josephine Passananti', 'Stanley Wu', 'Haitao Zheng', 'Ben Y. Zhao']",2024,sp,attack
Need for Speed: Taming Backdoor Attacks with Speed and Precision.,"['Zhuo Ma', 'Yilong Yang', 'Yang Liu', 'Tong Yang', 'Xinjing Liu', 'Teng Li', 'Zhan Qin']",2024,sp,attack
Test-Time Poisoning Attacks Against Test-Time Adaptation Models.,"['Tianshuo Cong', 'Xinlei He', 'Yun Shen', 'Yang Zhang']",2024,sp,attack
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge.,"['Jiahe Lan', 'Jie Wang', 'Baochen Yan', 'Zheng Yan', 'Elisa Bertino']",2024,sp,attack
MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.,"['Hang Wang', 'Zhen Xiang', 'David J. Miller', 'George Kesidis']",2024,sp,attack
BadVFL: Backdoor Attacks in Vertical Federated Learning.,"['Mohammad Naseri', 'Yufei Han', 'Emiliano De Cristofaro']",2024,sp,attack
Distribution Preserving Backdoor Attack in Self-supervised Learning.,"['Guanhong Tao', 'Zhenting Wang', 'Shiwei Feng', 'Guangyu Shen', 'Shiqing Ma', 'Xiangyu Zhang']",2024,sp,attack
Exploring the Orthogonality and Linearity of Backdoor Attacks.,"['Kaiyuan Zhang', 'Siyuan Cheng', 'Guangyu Shen', 'Guanhong Tao', 'Shengwei An', 'Anuran Makur', 'Shiqing Ma', 'Xiangyu Zhang']",2024,sp,attack
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.,"['Huming Qiu', 'Junjie Sun', 'Mi Zhang', 'Xudong Pan', 'Min Yang']",2024,sp,attack
FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks.,"['Ehsanul Kabir', 'Zeyu Song', 'Md. Rafi Ur Rashid', 'Shagufta Mehnaz']",2024,sp,attack
SHERPA: Explainable Robust Algorithms for Privacy-Preserved Federated Learning in Future Networks to Defend Against Data Poisoning Attacks.,"['Chamara Sandeepa', 'Bartlomiej Siniarski', 'Shen Wang', 'Madhusanka Liyanage']",2024,sp,attack
